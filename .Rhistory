#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 7]) + 1))/length(train_set[ , 7])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
#Training error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 7]) + 1))/length(test_set[ , 7])
}
plot(seq(0.001, 0.1, by = .001), test_error, xlab = "lambda")
title("Test error, interaction level = 1")
plot(seq(0.001, 0.1, by = .001), train_error, xlab = "lambda")
title("Train error, interaction level = 1")
#Looking at test error
min(test_error)
max(test_error)
median(test_error)
#Looking at important variables
summary(gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .01, n.trees = 1000))
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:6], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:6], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 100)
test_error <- vector(mode = "numeric", length = 100)
for (shrink_value in seq(0.001, .1, by = .001)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 2, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 2, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 7]) + 1))/length(train_set[ , 7])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 2, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
#Training error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 7]) + 1))/length(test_set[ , 7])
}
plot(seq(0.001, 0.1, by = .001), test_error, xlab = "lambda")
title("Test error, interaction level = 1")
plot(seq(0.001, 0.1, by = .001), train_error, xlab = "lambda")
title("Train error, interaction level = 1")
#Looking at test error
min(test_error)
max(test_error)
median(test_error)
#Looking at important variables
summary(gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .01, n.trees = 1000))
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:6], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:6], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 100)
test_error <- vector(mode = "numeric", length = 100)
for (shrink_value in seq(0.001, .1, by = .001)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 7]) + 1))/length(train_set[ , 7])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
#Training error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 7]) + 1))/length(test_set[ , 7])
}
plot(seq(0.001, 0.1, by = .001), test_error, xlab = "lambda")
title("Test error, interaction level = 1")
plot(seq(0.001, 0.1, by = .001), train_error, xlab = "lambda")
title("Train error, interaction level = 1")
#Looking at test error
min(test_error)
max(test_error)
median(test_error)
#Looking at important variables
summary(gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .01, n.trees = 1000))
#setting the seed
set.seed(1243)
#Bagging: Recall that is is just RF with m=p which is 6 in this case
bag.spam <- randomForest(yesno ~ ., data = train_set, mtry = 6, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.bag <- predict(bag.spam, newdata = test_set)
table(pred.test.bag, test_set$spam)
pred.test.bag <- predict(bag.spam, newdata = test_set)
table(pred.test.bag, test_set$yesno)
#setting the seed
set.seed(1243)
#Bagging: Recall that is is just RF with m=p which is 6 in this case
bag.spam <- randomForest(yesno ~ ., data = train_set, mtry = 6, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.bag <- predict(bag.spam, newdata = test_set)
table.tree <- table(pred.test.bag, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(bag.spam)
varImpPlot(bag.spam)
#Number of predictors
num_p <- length(new_auto[1, ]) - 1
#Number of predictors
num_p <- length(spam_data[1, ]) - 1
#sqrt{p}
sqrt(num_p)
#p/3
num_p/3
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf2.spam <- randomForest(yesno ~ ., data = train_set, mtry = 2, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf2 <- predict(rf2.spam, newdata = test_set)
table.tree <- table(pred.test.rf2, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf2.mpg)
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf2.spam <- randomForest(yesno ~ ., data = train_set, mtry = 2, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf2 <- predict(rf2.spam, newdata = test_set)
table.tree <- table(pred.test.rf2, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf2.spam)
varImpPlot(rf2.spam)
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf3.spam <- randomForest(yesno ~ ., data = train_set, mtry = 3, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf3 <- predict(rf3.spam, newdata = test_set)
table.tree <- table(pred.test.rf3, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf3.mpg)
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf3.spam <- randomForest(yesno ~ ., data = train_set, mtry = 3, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf3 <- predict(rf3.spam, newdata = test_set)
table.tree <- table(pred.test.rf3, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf3.spam)
varImpPlot(rf3.spam)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(gt) #for nice tables
library(tidyverse) #for nice everything else
#packages for trees
library(ISLR)
library(tree)
library(randomForest)
library(gbm)
#We're going to use this one!!!!
spam_small <- tidytuesdayR::tt_load('2023-08-15')
head(spam_small)
spam_data <- data.frame(spam_small$spam)
spam_data$yesno <- as.factor(spam_data$yesno)
#Set seed
set.seed(123)
#number of observations
obs_num <- length(spam_data[ , 1])
#Randomly split training data to test data in the ratio of (1:1)
sampling_choice <- sample(1:obs_num, size = floor(obs_num/2))
train_set <- spam_data[sampling_choice, ]
test_set <- spam_data[-sampling_choice, ]
#Classification tree used to predict yesno using all variables as predictors
tree.spam <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(tree.spam)
#Plot of tree
plot(tree.spam)
text(tree.spam, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Unpruned Classification Tree")
#Predicting the classification of the test_set using the unpruned tree
tree.predict.spam <- predict(tree.spam, test_set, type = "class")
#Resulting table of prediction vs true values
table.tree <- table(tree.predict.spam, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Setting seed because of cross validation
set.seed(1243)
#Performs cross validation of the unpruned tree to determine the "best" pruning; the last argument specifies that pruning should be done using the misclassification error rate
cv.tree.spam <- cv.tree(tree.spam, FUN = prune.misclass)
cv.tree.spam
#creating the pruned tree with 6 terminal nodes
pruned.tree.spam <- prune.misclass(tree.spam, best = 4)
#Plotting the tree
plot(pruned.tree.spam)
text(pruned.tree.spam, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Pruned Classification Tree")
#Predicting the classification of the test_set using the pruned tree
tree.predict.spam <- predict(pruned.tree.spam, test_set, type = "class")
#Resulting table of prediction vs true values
table.tree <- table(tree.predict.spam, test_set$yesno)
gt(data.frame(Truth_nonspam = table.tree[ , 1], Truth_spam = table.tree[ , 2], row.names = c("Class_nonspam", "Class_spam")), rownames_to_stub = TRUE)
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:6], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:6], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 100)
test_error <- vector(mode = "numeric", length = 100)
for (shrink_value in seq(0.001, .1, by = .001)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000, cv.folds = 5)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 7]) + 1))/length(train_set[ , 7])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 7]) + 1))/length(test_set[ , 7])
}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(gt) #for nice tables
library(tidyverse) #for nice everything else
#packages for trees
library(ISLR)
library(tree)
library(randomForest)
library(gbm)
#We're going to use this one!!!!
spam_small <- tidytuesdayR::tt_load('2023-08-15')
head(spam_small)
spam_data <- data.frame(spam_small$spam)
spam_data$yesno <- as.factor(spam_data$yesno)
#Set seed
set.seed(123)
#number of observations
obs_num <- length(spam_data[ , 1])
#Randomly split training data to test data in the ratio of (1:1)
sampling_choice <- sample(1:obs_num, size = floor(obs_num/2))
train_set <- spam_data[sampling_choice, ]
test_set <- spam_data[-sampling_choice, ]
#Classification tree used to predict yesno using all variables as predictors
tree.spam <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(tree.spam)
#Plot of tree
plot(tree.spam)
text(tree.spam, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Unpruned Classification Tree")
#Predicting the classification of the test_set using the unpruned tree
tree.predict.spam <- predict(tree.spam, test_set, type = "class")
#Resulting table of prediction vs true values
table.tree <- table(tree.predict.spam, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Setting seed because of cross validation
set.seed(1243)
#Performs cross validation of the unpruned tree to determine the "best" pruning; the last argument specifies that pruning should be done using the misclassification error rate
cv.tree.spam <- cv.tree(tree.spam, FUN = prune.misclass)
cv.tree.spam
#creating the pruned tree with 6 terminal nodes
pruned.tree.spam <- prune.misclass(tree.spam, best = 4)
#Plotting the tree
plot(pruned.tree.spam)
text(pruned.tree.spam, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Pruned Classification Tree")
#Predicting the classification of the test_set using the pruned tree
tree.predict.spam <- predict(pruned.tree.spam, test_set, type = "class")
#Resulting table of prediction vs true values
table.tree <- table(tree.predict.spam, test_set$yesno)
gt(data.frame(Truth_nonspam = table.tree[ , 1], Truth_spam = table.tree[ , 2], row.names = c("Class_nonspam", "Class_spam")), rownames_to_stub = TRUE)
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:6], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:6], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 10)
test_error <- vector(mode = "numeric", length = 10)
cv_error <- vector(mode = "numeric", length = 10)
for (shrink_value in seq(0.01, .1, by = .01)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000, cv.folds = 5)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.01] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 7]) + 1))/length(train_set[ , 7])
#CV Error
cv_error[shrink_value/.01] <- mean(boost.spam$cv.error)
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
test_error[shrink_value/.01] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 7]) + 1))/length(test_set[ , 7])
}
plot(seq(0.01, 0.1, by = .01), test_error, xlab = "lambda")
title("Test error, interaction level = 1")
plot(seq(0.01, 0.1, by = .01), cv_error, xlab = "lambda")
title("CV error, interaction level = 1")
plot(seq(0.01, 0.1, by = .01), train_error, xlab = "lambda")
title("Train error, interaction level = 1")
#Looking at test error
min(test_error)
max(test_error)
median(test_error)
#Using shrinkage level .06 (found using cv)
boost.spam.06 <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .06, n.trees = 1000)
#Looking at important variables
summary(boost.spam.06)
#Predicting the classification of the test_set using the boosted tree
tree.predict.spam <- 1*(predict(boost.spam.06, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .06, n.trees = 1000) > 0)
#Resulting table of prediction vs true values
table.tree <- table(tree.predict.spam, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
summary(boost.spam.06)
#Resulting table of prediction vs true values
gt(data.frame(Truth_nonspam = table.tree[ , 1], Truth_spam = table.tree[ , 2], row.names = c("Class_nonspam", "Class_spam")), rownames_to_stub = TRUE)
#Looking at test error
min(test_error)
max(test_error)
median(test_error)
#Using shrinkage level .06 (found using cv)
boost.spam.06 <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .06, n.trees = 1000)
#Looking at important variables
summary(boost.spam.06)
#Predicting the classification of the test_set using the boosted tree
tree.predict.spam <- 1*(predict(boost.spam.06, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .06, n.trees = 1000) > 0)
#Resulting table of prediction vs true values
table.tree <- table(tree.predict.spam, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
summary(boost.spam.06)
summary(boost.spam.06)$table
summary(boost.spam.06)[1]
summary(boost.spam.06)[2]
summary(boost.spam.06)[3]
str(summary(boost.spam.06))
plot(summary(boost.spam.06))
plot(summary(boost.spam.06))
plot(seq(0.01, 0.1, by = .01), test_error, xlab = "lambda")
title("Test error, interaction level = 1")
plot(seq(0.01, 0.1, by = .01), cv_error, xlab = "lambda")
title("CV error, interaction level = 1")
plot(seq(0.01, 0.1, by = .01), train_error, xlab = "lambda")
title("Train error, interaction level = 1")
min(test_error)
max(test_error)
median(test_error)
test_error
#setting the seed
set.seed(1243)
#Bagging: Recall that is is just RF with m=p which is 6 in this case
bag.spam <- randomForest(yesno ~ ., data = train_set, mtry = 6, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.bag <- predict(bag.spam, newdata = test_set)
table.tree <- table(pred.test.bag, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(bag.spam)
varImpPlot(bag.spam)
#Looking at important variables
summary(boost.spam.06)
#Resulting table of prediction vs true values
gt(data.frame(Truth_nonspam = table.tree[ , 1], Truth_spam = table.tree[ , 2], row.names = c("Class_nonspam", "Class_spam")), rownames_to_stub = TRUE)
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf2.spam <- randomForest(yesno ~ ., data = train_set, mtry = 2, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf2 <- predict(rf2.spam, newdata = test_set)
table.tree <- table(pred.test.rf2, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf2.spam)
varImpPlot(rf2.spam)
#Resulting table of prediction vs true values
gt(data.frame(Truth_nonspam = table.tree[ , 1], Truth_spam = table.tree[ , 2], row.names = c("Classified_nonspam", "Classified_spam")), rownames_to_stub = TRUE)
#setting the seed
set.seed(1243)
#Bagging: Recall that is is just RF with m=p which is 6 in this case
bag.spam <- randomForest(yesno ~ ., data = train_set, mtry = 6, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.bag <- predict(bag.spam, newdata = test_set)
table.tree <- table(pred.test.bag, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(bag.spam)
varImpPlot(bag.spam)
