#We're going to use this one!!!!
spam_small <- tidytuesdayR::tt_load('2023-08-15')
head(spam_small)
str(spam_small)
#Set seed
set.seed(123)
#number of observations
obs_num <- length(spam_small[ ,1])
spam_small[ , 1]
spam_small
#We're going to use this one!!!!
spam_small <- tidytuesdayR::tt_load('2023-08-15')
head(spam_small)
spam_small$spam
#We're going to use this one!!!!
spam_small <- tidytuesdayR::tt_load('2023-08-15')
head(spam_small)
spam_data <- spam_small$spam
obs_num <- length(spam_data[ , 1])
obs_num
spam_data[ , 1]
#We're going to use this one!!!!
spam_small <- tidytuesdayR::tt_load('2023-08-15')
head(spam_small)
spam_data <- data.frame(spam_small$spam)
spam_data
length(spam_data[ , 1])
#Set seed
set.seed(123)
#number of observations
obs_num <- length(spam_data[ , 1])
#Randomly split training data to test data in the ratio of (3:1)=(294:98)
sampling_choice <- sample(1:obs_num, size = floor(obs_num/2))
train_set <- new_auto[sampling_choice, ]
#Set seed
set.seed(123)
#number of observations
obs_num <- length(spam_data[ , 1])
#Randomly split training data to test data in the ratio of (3:1)=(294:98)
sampling_choice <- sample(1:obs_num, size = floor(obs_num/2))
train_set <- spam_data[sampling_choice, ]
test_set <- spam_data[-sampling_choice, ]
head(spam_data)
#Classification tree used to predict mpg01 using all variables as predictors
tree.mpg <- tree(mpg01 ~ ., data = train_set)
#Classification tree used to predict mpg01 using all variables as predictors
tree.mpg <- tree(yesno ~ ., data = train_set)
#packages for trees
library(ISLR)
library(tree)
library(randomForest)
library(gbm)
#Classification tree used to predict mpg01 using all variables as predictors
tree.mpg <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(yesno ~ tree.mpg)
str(spam_data)
#We're going to use this one!!!!
spam_small <- tidytuesdayR::tt_load('2023-08-15')
head(spam_small)
spam_data <- data.frame(spam_small$spam)
spam_data$yesno <- as.factor(spam_data$yesno)
str(spam_data)
#Set seed
set.seed(123)
#number of observations
obs_num <- length(spam_data[ , 1])
#Randomly split training data to test data in the ratio of (3:1)=(294:98)
sampling_choice <- sample(1:obs_num, size = floor(obs_num/2))
train_set <- spam_data[sampling_choice, ]
test_set <- spam_data[-sampling_choice, ]
#Classification tree used to predict mpg01 using all variables as predictors
tree.mpg <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(yesno ~ tree.mpg)
#Classification tree used to predict mpg01 using all variables as predictors
tree.mpg <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(tree.mpg)
#Classification tree used to predict mpg01 using all variables as predictors
tree.mpg <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(tree.mpg)
#Plot of tree
plot(tree.mpg)
text(tree.mpg, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Unpruned Classification Tree")
#Classification tree used to predict mpg01 using all variables as predictors
tree.mpg <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(tree.mpg)
#Plot of tree
plot(tree.mpg)
text(tree.mpg, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Unpruned Classification Tree")
#Predicting the classification of the test_set using the unpruned tree
tree.predict.mpg <- predict(tree.mpg, test_set, type = "class")
#Resulting table of prediction vs true values
table(tree.predict.mpg, test_set$mpg01)
#Classification tree used to predict mpg01 using all variables as predictors
tree.spam <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(tree.spam)
#Plot of tree
plot(tree.spam)
text(tree.spam, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Unpruned Classification Tree")
#Predicting the classification of the test_set using the unpruned tree
tree.predict.spam <- predict(tree.spam, test_set, type = "class")
#Resulting table of prediction vs true values
table(tree.predict.spam, test_set$yesno)
table.tree <- table(tree.predict.spam, test_set$yesno)
table.tree
table.tree[1,2]
table.tree[2,2]/(table.tree[2,2]+table.tree[1,2])
table.tree[2,2]+table.tree[1,2]
str(test_set)
str(test_set$yesno)
sum(test_set$yesno=="n")
sum(test_set$yesno=="y")
#Classification tree used to predict mpg01 using all variables as predictors
tree.spam <- tree(yesno ~ ., data = train_set)
#Summary that includes used variables, residual mean deviance (similar to entropy), and the training error rate (aka Misclassification error rate)
summary(tree.spam)
#Plot of tree
plot(tree.spam)
text(tree.spam, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Unpruned Classification Tree")
#Predicting the classification of the test_set using the unpruned tree
tree.predict.spam <- predict(tree.spam, test_set, type = "class")
#Resulting table of prediction vs true values
table.tree <- table(tree.predict.spam, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Setting seed because of cross validation
set.seed(1243)
#Performs cross validation of the unpruned tree to determine the "best" pruning; the last argument specifies that pruning should be done using the misclassification error rate
cv.tree.spam <- cv.tree(tree.spam, FUN = prune.misclass)
cv.tree.spam
#Setting seed because of cross validation
set.seed(1243)
#Performs cross validation of the unpruned tree to determine the "best" pruning; the last argument specifies that pruning should be done using the misclassification error rate
cv.tree.spam <- cv.tree(tree.spam, FUN = prune.misclass)
cv.tree.spam
#plotting size by cv error
plot(cv.tree.mpg$size, cv.tree.mpg$dev, type = "b")
#Setting seed because of cross validation
set.seed(1243)
#Performs cross validation of the unpruned tree to determine the "best" pruning; the last argument specifies that pruning should be done using the misclassification error rate
cv.tree.spam <- cv.tree(tree.spam, FUN = prune.misclass)
cv.tree.spam
#plotting size by cv error
plot(cv.tree.spam$size, cv.tree.spam$dev, type = "b")
#Setting seed because of cross validation
set.seed(1243)
#Performs cross validation of the unpruned tree to determine the "best" pruning; the last argument specifies that pruning should be done using the misclassification error rate
cv.tree.spam <- cv.tree(tree.spam, FUN = prune.misclass)
cv.tree.spam
#creating the pruned tree with 6 terminal nodes
pruned.tree.spam <- prune.misclass(tree.spam, best = 4)
#Plotting the tree
plot(pruned.tree.spam)
text(pruned.tree.spam, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Pruned Classification Tree")
#Setting seed because of cross validation
set.seed(1243)
#Performs cross validation of the unpruned tree to determine the "best" pruning; the last argument specifies that pruning should be done using the misclassification error rate
cv.tree.spam <- cv.tree(tree.spam, FUN = prune.misclass)
cv.tree.spam
#creating the pruned tree with 6 terminal nodes
pruned.tree.spam <- prune.misclass(tree.spam, best = 4)
#Plotting the tree
plot(pruned.tree.spam)
text(pruned.tree.spam, pretty = 0, cex = .5, adj = c(.5, 1))
title(main = "Pruned Classification Tree")
#Predicting the classification of the test_set using the pruned tree
tree.predict.spam <- predict(pruned.tree.spam, test_set, type = "class")
#Resulting table of prediction vs true values
table.tree <- table(tree.predict.spam, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
train_set[1:5,]
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:7], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:7], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 100)
test_error <- vector(mode = "numeric", length = 100)
for (shrink_value in seq(0.001, .1, by = .001)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 8]) + 1))/length(train_set[ , 8])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
#Training error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 8]) + 1))/length(test_set[ , 8])
}
train_set_bern
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:6], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:6], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 100)
test_error <- vector(mode = "numeric", length = 100)
for (shrink_value in seq(0.001, .1, by = .001)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 8]) + 1))/length(train_set[ , 8])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
#Training error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 8]) + 1))/length(test_set[ , 8])
}
train_set_bern
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:6], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:6], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 100)
test_error <- vector(mode = "numeric", length = 100)
for (shrink_value in seq(0.001, .1, by = .001)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 7]) + 1))/length(train_set[ , 7])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
#Training error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 7]) + 1))/length(test_set[ , 7])
}
plot(seq(0.001, 0.1, by = .001), test_error, xlab = "lambda")
title("Test error, interaction level = 1")
plot(seq(0.001, 0.1, by = .001), train_error, xlab = "lambda")
title("Train error, interaction level = 1")
#Looking at test error
min(test_error)
max(test_error)
median(test_error)
#Looking at important variables
summary(gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .01, n.trees = 1000))
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:6], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:6], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 100)
test_error <- vector(mode = "numeric", length = 100)
for (shrink_value in seq(0.001, .1, by = .001)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 2, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 2, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 7]) + 1))/length(train_set[ , 7])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 2, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
#Training error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 7]) + 1))/length(test_set[ , 7])
}
plot(seq(0.001, 0.1, by = .001), test_error, xlab = "lambda")
title("Test error, interaction level = 1")
plot(seq(0.001, 0.1, by = .001), train_error, xlab = "lambda")
title("Train error, interaction level = 1")
#Looking at test error
min(test_error)
max(test_error)
median(test_error)
#Looking at important variables
summary(gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .01, n.trees = 1000))
#setting the seed
set.seed(1243)
#(Finally figured out that the response needs to be numeric 0,1 rather than a factor) This converts yesno from a factor to a Bernoulli variable
train_set_bern <- cbind(train_set[ , 1:6], yesno = as.numeric(train_set[ , 7]) - 1)
test_set_bern <- cbind(test_set[ , 1:6], yesno = as.numeric(test_set[ , 7]) - 1)
#Boosted tree with an interaction depth max of 1 (so, stumps) across vary shrinkage values
train_error <- vector(mode = "numeric", length = 100)
test_error <- vector(mode = "numeric", length = 100)
for (shrink_value in seq(0.001, .1, by = .001)) {
#Fit a boosted model
boost.spam <- gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000)
#Some research makes me believe that prediction gives out the log-odds. Thus, a value <0 will be transformed to 0 and a value >0 will be transformed to 1. Note to self: Look up ?gbm.object in help for why I came to this conclusion. Look under "fit" description.
#Training predictions
train.boost.pred <- 1*(predict(boost.spam, newdata = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Training error
train_error[shrink_value/.001] <- sum(abs(train.boost.pred - as.numeric(train_set[ , 7]) + 1))/length(train_set[ , 7])
#Test predictions
test.boost.pred <- 1*(predict(boost.spam, newdata = test_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = shrink_value, n.trees = 1000) > 0)
#Test error
#Training error
test_error[shrink_value/.001] <- sum(abs(test.boost.pred - as.numeric(test_set[ , 7]) + 1))/length(test_set[ , 7])
}
plot(seq(0.001, 0.1, by = .001), test_error, xlab = "lambda")
title("Test error, interaction level = 1")
plot(seq(0.001, 0.1, by = .001), train_error, xlab = "lambda")
title("Train error, interaction level = 1")
#Looking at test error
min(test_error)
max(test_error)
median(test_error)
#Looking at important variables
summary(gbm(yesno ~ ., data = train_set_bern, interaction.depth = 1, distribution = "bernoulli", shrinkage = .01, n.trees = 1000))
#setting the seed
set.seed(1243)
#Bagging: Recall that is is just RF with m=p which is 6 in this case
bag.spam <- randomForest(yesno ~ ., data = train_set, mtry = 6, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.bag <- predict(bag.spam, newdata = test_set)
table(pred.test.bag, test_set$spam)
pred.test.bag <- predict(bag.spam, newdata = test_set)
table(pred.test.bag, test_set$yesno)
#setting the seed
set.seed(1243)
#Bagging: Recall that is is just RF with m=p which is 6 in this case
bag.spam <- randomForest(yesno ~ ., data = train_set, mtry = 6, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.bag <- predict(bag.spam, newdata = test_set)
table.tree <- table(pred.test.bag, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(bag.spam)
varImpPlot(bag.spam)
#Number of predictors
num_p <- length(new_auto[1, ]) - 1
#Number of predictors
num_p <- length(spam_data[1, ]) - 1
#sqrt{p}
sqrt(num_p)
#p/3
num_p/3
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf2.spam <- randomForest(yesno ~ ., data = train_set, mtry = 2, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf2 <- predict(rf2.spam, newdata = test_set)
table.tree <- table(pred.test.rf2, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf2.mpg)
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf2.spam <- randomForest(yesno ~ ., data = train_set, mtry = 2, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf2 <- predict(rf2.spam, newdata = test_set)
table.tree <- table(pred.test.rf2, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf2.spam)
varImpPlot(rf2.spam)
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf3.spam <- randomForest(yesno ~ ., data = train_set, mtry = 3, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf3 <- predict(rf3.spam, newdata = test_set)
table.tree <- table(pred.test.rf3, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf3.mpg)
#setting the seed
set.seed(1243)
#RF with 2 predictors
rf3.spam <- randomForest(yesno ~ ., data = train_set, mtry = 3, importance = TRUE, ntree = 1000)
#The confusion matrix for the training set
bag.spam
#Predicting on the test set
pred.test.rf3 <- predict(rf3.spam, newdata = test_set)
table.tree <- table(pred.test.rf3, test_set$yesno)
table.tree
#Resulting correctness
#Spam ID
table.tree[2,2]/(table.tree[2,2] + table.tree[1,2])
#Not Spam ID
table.tree[1,1]/(table.tree[1,1] + table.tree[2,1])
#Overall
(table.tree[2,2] + table.tree[1,1])/(table.tree[2,2] + table.tree[1,2] + table.tree[1,1] + table.tree[2,1])
#Finding what variables are important
importance(rf3.spam)
varImpPlot(rf3.spam)
